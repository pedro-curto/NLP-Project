{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genre value counts\n",
      "Genre\n",
      "drama        1676\n",
      "comedy       1193\n",
      "horror       1108\n",
      "action       1059\n",
      "romance       886\n",
      "western       829\n",
      "crime         541\n",
      "animation     535\n",
      "sci-fi        214\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../datasets/train.txt', sep='\\t', header=None, names=['Title', 'Origin', 'Genre', 'Director', 'Plot'])\n",
    "\n",
    "print(\"Genre value counts\")\n",
    "print(data['Genre'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Director</th>\n",
       "      <th>Plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ela Cheppanu</td>\n",
       "      <td>Telugu</td>\n",
       "      <td>romance</td>\n",
       "      <td>Ramana</td>\n",
       "      <td>Sekhar (Tarun) is a graduate from IIM and work...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Nightmare on Elm Street</td>\n",
       "      <td>American</td>\n",
       "      <td>horror</td>\n",
       "      <td>Samuel Bayer</td>\n",
       "      <td>Kris Fowles (Katie Cassidy) goes to the Spring...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>American Gothic</td>\n",
       "      <td>American</td>\n",
       "      <td>horror</td>\n",
       "      <td>John Hough</td>\n",
       "      <td>Cynthia is traumatized by the death of her bab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gang</td>\n",
       "      <td>Bollywood</td>\n",
       "      <td>crime</td>\n",
       "      <td>Mazhar Khan</td>\n",
       "      <td>Four friends, Gangu (Jackie Shroff), Abdul (Na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Intimate Relations</td>\n",
       "      <td>British</td>\n",
       "      <td>drama</td>\n",
       "      <td>Charles Frank</td>\n",
       "      <td>Crisis in a middle-class family when the son f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Title     Origin    Genre       Director  \\\n",
       "0               Ela Cheppanu     Telugu  romance         Ramana   \n",
       "1  A Nightmare on Elm Street   American   horror   Samuel Bayer   \n",
       "2            American Gothic   American   horror     John Hough   \n",
       "3                       Gang  Bollywood    crime    Mazhar Khan   \n",
       "4         Intimate Relations    British    drama  Charles Frank   \n",
       "\n",
       "                                                Plot  \n",
       "0  Sekhar (Tarun) is a graduate from IIM and work...  \n",
       "1  Kris Fowles (Katie Cassidy) goes to the Spring...  \n",
       "2  Cynthia is traumatized by the death of her bab...  \n",
       "3  Four friends, Gangu (Jackie Shroff), Abdul (Na...  \n",
       "4  Crisis in a middle-class family when the son f...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop Words + Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:27: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:27: SyntaxWarning: invalid escape sequence '\\s'\n",
      "/tmp/ipykernel_202687/1285755728.py:27: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  text = re.sub('\\s+', ' ', text)\n"
     ]
    }
   ],
   "source": [
    "stop_words = [\"the\", \"to\", \"of\", \"a\", 'and', 'is', 'his', 'in', 'he', \n",
    "            'that', 'her', \"with\", \"by\", \"for\", \"him\", \"the\", \"as\", \"who\",\n",
    "            \"on\", \"she\", \"but\", \"from\", \"has\", \"they\", \"an\", \"at\", \"their\", \"are\",\n",
    "            \"into\", \"he\", \"out\", \"it\", \"up\", \"be\", \"was\", \"when\", \"not\", \"them\", \"which\",\n",
    "            \"then\", \"after\", \"about\", \"where\", \"one\", \"have\", \"When\", \"After\", \"tells\", \"him.\",\n",
    "            \"back\", \"She\", \"will\", \"while\", \"all\", \"two\", \"In\", \"had\", \"been\", \"They\",\n",
    "            \"get\", \"only\", \"also\", \"before\", \"off\", \"being\", \"As\", \"goes\", \"takes\",\n",
    "            \"this\", \"other\", \"take\", \"tries\", \"A\", \"her.\", \"go\", \"gets\", \"can\", \"man\", \"so\",\n",
    "            \"over\", \"through\", \"down\", \"help\", \"new\", \"him,\", \"now\", \"comes\", \"next\", \"himself\",\n",
    "            \"later\", \"however\", \"away\", \"there\", \"during\", \"both\", \"first\", \"again\", \"no\", \"way\", \"own\",\n",
    "            \"some\", \"another\", \"more\", \"becomes\", \"make\", \"does\", \"what\", \"begins\", \"meanwhile\", \"just\",\n",
    "            \"asks\", \"if\", \"because\", \"soon\", \"having\", \"its\", \"eventually\", \"come\", \"still\", \"between\", \"father\",\n",
    "            \"house\", \"finds\"\n",
    "            ]\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"can not \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = re.sub(r\"[^a-zA-Z]\", \" \", text)\n",
    "    text = text.strip(' ')\n",
    "    tokens = text.split()\n",
    "    filtered = [word for word in tokens if word not in stop_words]\n",
    "    return ' '.join(filtered)\n",
    "\n",
    "data['Clean_Plot'] = data['Plot'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['Clean_Plot'].values\n",
    "y = data['Genre'].values \n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bad results with Count Vectorizer, just meant to test\n",
    "count_vectorizer = CountVectorizer(stop_words=stop_words, ngram_range=(1, 3))\n",
    "X_train_counts = count_vectorizer.fit_transform(X_train)\n",
    "X_test_counts = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model + Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "svm_classifier = SVC(kernel='linear')\n",
    "svm_classifier.fit(X_train_counts, y_train)\n",
    "y_pred = svm_classifier.predict(X_test_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\")\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "# 0.54 accuracy with a strange confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GloVe for feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "glove_file = '../glove.6B/glove.6B.100d.txt'\n",
    "\n",
    "def load_glove_embeddings(glove_file):\n",
    "    embeddings_index = {}\n",
    "    with open(glove_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            embedding_vector = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = embedding_vector\n",
    "    return embeddings_index\n",
    "\n",
    "embeddings_index = load_glove_embeddings(glove_file)\n",
    "print(f\"Loaded {len(embeddings_index)} word vectors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_average_embedding(text, embeddings_index, embedding_dim=100):\n",
    "    words = text.split()  # very basic tokenization\n",
    "    embedding_matrix = []\n",
    "    \n",
    "    for word in words:\n",
    "        if word in embeddings_index:\n",
    "            embedding_matrix.append(embeddings_index[word])\n",
    "        else:\n",
    "            embedding_matrix.append(np.zeros(embedding_dim))  # uses a zero vector for unknown words\n",
    "    \n",
    "    if len(embedding_matrix) > 0:\n",
    "        # we calculate the average embeddings\n",
    "        return np.mean(embedding_matrix, axis=0)\n",
    "    else:\n",
    "        return np.zeros(embedding_dim)  # returns zero vector if no embeddings found\n",
    "\n",
    "X = data['Clean_Plot'].values\n",
    "embedding_dim = 100 # because we're using the 100-dim GloVe vectors\n",
    "X_embeddings = np.array([get_average_embedding(plot, embeddings_index, embedding_dim) for plot in X])\n",
    "print(X_embeddings.shape, embedding_dim, X_embeddings.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Give it to SVC (SVC with GloVe embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "y = label_encoder.fit_transform(data['Genre'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_embeddings, y, test_size=0.2, random_state=42)\n",
    "\n",
    "svc = SVC(kernel='linear')\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svc.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\")\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "# 0.62 accuracy, better confusion matrix but still not very good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, we test tf-idf to calculate embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "X_train_text, X_test_text, y_train, y_test = train_test_split(data['Clean_Plot'], y, test_size=0.2, random_state=42)\n",
    "\n",
    "tfidf = TfidfVectorizer(min_df=20, stop_words=stop_words, ngram_range=(1, 3))\n",
    "\n",
    "X_train = tfidf.fit_transform(X_train_text)\n",
    "X_test = tfidf.transform(X_test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And we test the embeddings with the SVC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(kernel='linear', C=1)\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svc.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# 0.643 accuracy is the best so far; the same issues arise with the confusion matrix and the plots, basically \n",
    "# grid search and a lot of testing found best parameters are linear kernel and C=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassified_indices = np.where(y_pred != y_test)[0]\n",
    "\n",
    "true_labels = label_encoder.inverse_transform(y_test)\n",
    "predicted_labels = label_encoder.inverse_transform(y_pred)\n",
    "misclassified_plots = X_test_text.iloc[misclassified_indices]\n",
    "misclassified_true_labels = true_labels[misclassified_indices]\n",
    "misclassified_predicted_labels = predicted_labels[misclassified_indices]\n",
    "\n",
    "with open('mispredictions.txt', 'w', encoding='utf-8') as f:\n",
    "    for plot, true_label, pred_label in zip(\n",
    "        misclassified_plots,\n",
    "        misclassified_true_labels,\n",
    "        misclassified_predicted_labels\n",
    "    ):\n",
    "        f.write(f\"Plot: {plot}\\n\")\n",
    "        f.write(f\"True Label: {true_label}\\n\")\n",
    "        f.write(f\"Predicted Label: {pred_label}\\n\")\n",
    "        f.write(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
